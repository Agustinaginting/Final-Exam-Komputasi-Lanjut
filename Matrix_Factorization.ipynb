{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOz6J0nhBVfYbYEAfmhBmhZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Agustinaginting/Final-Exam-Komputasi-Lanjut/blob/main/Matrix_Factorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download useful files"
      ],
      "metadata": {
        "id": "pZGgoGfmkb1W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCuBdMYtkKMP",
        "outputId": "265ba37d-5611-464c-d574-7da41f997bfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-03 09:54:26--  https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nzhinusoftcm/review-on-collaborative-filtering/master/recsys.zip [following]\n",
            "--2023-01-03 09:54:26--  https://raw.githubusercontent.com/nzhinusoftcm/review-on-collaborative-filtering/master/recsys.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15312323 (15M) [application/zip]\n",
            "Saving to: ‘recsys.zip’\n",
            "\n",
            "recsys.zip          100%[===================>]  14.60M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-01-03 09:54:27 (131 MB/s) - ‘recsys.zip’ saved [15312323/15312323]\n",
            "\n",
            "Archive:  recsys.zip\n",
            "   creating: recsys/\n",
            "  inflating: recsys/datasets.py      \n",
            "  inflating: recsys/preprocessing.py  \n",
            "  inflating: recsys/utils.py         \n",
            "  inflating: recsys/requirements.txt  \n",
            "   creating: recsys/.vscode/\n",
            "  inflating: recsys/.vscode/settings.json  \n",
            "   creating: recsys/__pycache__/\n",
            "  inflating: recsys/__pycache__/datasets.cpython-36.pyc  \n",
            "  inflating: recsys/__pycache__/datasets.cpython-37.pyc  \n",
            "  inflating: recsys/__pycache__/utils.cpython-36.pyc  \n",
            "  inflating: recsys/__pycache__/preprocessing.cpython-37.pyc  \n",
            "  inflating: recsys/__pycache__/datasets.cpython-38.pyc  \n",
            "  inflating: recsys/__pycache__/preprocessing.cpython-36.pyc  \n",
            "  inflating: recsys/__pycache__/preprocessing.cpython-38.pyc  \n",
            "   creating: recsys/memories/\n",
            "  inflating: recsys/memories/ItemToItem.py  \n",
            "  inflating: recsys/memories/UserToUser.py  \n",
            "   creating: recsys/memories/__pycache__/\n",
            "  inflating: recsys/memories/__pycache__/UserToUser.cpython-36.pyc  \n",
            "  inflating: recsys/memories/__pycache__/UserToUser.cpython-37.pyc  \n",
            "  inflating: recsys/memories/__pycache__/ItemToItem.cpython-37.pyc  \n",
            "  inflating: recsys/memories/__pycache__/user2user.cpython-36.pyc  \n",
            "  inflating: recsys/memories/__pycache__/ItemToItem.cpython-36.pyc  \n",
            "   creating: recsys/models/\n",
            "  inflating: recsys/models/SVD.py    \n",
            "  inflating: recsys/models/MatrixFactorization.py  \n",
            "  inflating: recsys/models/ExplainableMF.py  \n",
            "  inflating: recsys/models/NonnegativeMF.py  \n",
            "   creating: recsys/models/__pycache__/\n",
            "  inflating: recsys/models/__pycache__/SVD.cpython-36.pyc  \n",
            "  inflating: recsys/models/__pycache__/MatrixFactorization.cpython-37.pyc  \n",
            "  inflating: recsys/models/__pycache__/ExplainableMF.cpython-36.pyc  \n",
            "  inflating: recsys/models/__pycache__/ExplainableMF.cpython-37.pyc  \n",
            "  inflating: recsys/models/__pycache__/MatrixFactorization.cpython-36.pyc  \n",
            "   creating: recsys/metrics/\n",
            "  inflating: recsys/metrics/EvaluationMetrics.py  \n",
            "   creating: recsys/img/\n",
            "  inflating: recsys/img/MF-and-NNMF.png  \n",
            "  inflating: recsys/img/svd.png      \n",
            "  inflating: recsys/img/MF.png       \n",
            "   creating: recsys/predictions/\n",
            "   creating: recsys/predictions/item2item/\n",
            "   creating: recsys/weights/\n",
            "   creating: recsys/weights/item2item/\n",
            "   creating: recsys/weights/item2item/ml1m/\n",
            "  inflating: recsys/weights/item2item/ml1m/similarities.npy  \n",
            "  inflating: recsys/weights/item2item/ml1m/neighbors.npy  \n",
            "   creating: recsys/weights/item2item/ml100k/\n",
            "  inflating: recsys/weights/item2item/ml100k/similarities.npy  \n",
            "  inflating: recsys/weights/item2item/ml100k/neighbors.npy  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not (os.path.exists(\"recsys.zip\") or os.path.exists(\"recsys\")):\n",
        "    !wget https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip    \n",
        "    !unzip recsys.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import requirements\n",
        "\n",
        "matplotlib==3.2.2\n",
        "numpy==1.19.2\n",
        "pandas==1.0.5\n",
        "python==3.7\n",
        "scikit-learn==0.24.1\n",
        "scikit-surprise==1.1.1\n",
        "scipy==1.6.2"
      ],
      "metadata": {
        "id": "KRhe_DK7kgbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Library atau package\n",
        "from recsys.preprocessing import mean_ratings\n",
        "from recsys.preprocessing import normalized_ratings\n",
        "from recsys.preprocessing import ids_encoder\n",
        "from recsys.preprocessing import train_test_split\n",
        "from recsys.preprocessing import rating_matrix\n",
        "from recsys.preprocessing import get_examples\n",
        "from recsys.preprocessing import scale_ratings\n",
        "\n",
        "from recsys.datasets import ml100k\n",
        "from recsys.datasets import ml1m\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "RnaCBDT9kh0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pendefinisian Model "
      ],
      "metadata": {
        "id": "t4yVTMtbklgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pendefinisian Model \n",
        "class MatrixFactorization:\n",
        "    \n",
        "    def __init__(self, m, n, k=10, alpha=0.001, lamb=0.01):\n",
        "        \"\"\"\n",
        "        Initialization of the model        \n",
        "        : param\n",
        "            - m : number of users\n",
        "            - n : number of items\n",
        "            - k : length of latent factor, both for users and items. 50 by default\n",
        "            - alpha : learning rate. 0.001 by default\n",
        "            - lamb : regularizer parameter. 0.02 by default\n",
        "        \"\"\"\n",
        "        np.random.seed(32)\n",
        "        \n",
        "        # initialize the latent factor matrices P and Q (of shapes (m,k) and (n,k) respectively) that will be learnt\n",
        "        self.k = k\n",
        "        self.P = np.random.normal(size=(m, k))\n",
        "        self.Q = np.random.normal(size=(n, k))\n",
        "        \n",
        "        # hyperparameter initialization\n",
        "        self.alpha = alpha\n",
        "        self.lamb = lamb\n",
        "        \n",
        "        # training history\n",
        "        self.history = {\n",
        "            \"epochs\":[],\n",
        "            \"loss\":[],\n",
        "            \"val_loss\":[],\n",
        "            \"lr\":[]\n",
        "        }\n",
        "    \n",
        "    def print_training_parameters(self):\n",
        "        print('Training Matrix Factorization Model ...')\n",
        "        print(f'k={self.k} \\t alpha={self.alpha} \\t lambda={self.lamb}')\n",
        "    \n",
        "    def update_rule(self, u, i, error):\n",
        "        self.P[u] = self.P[u] + self.alpha * (error * self.Q[i] - self.lamb * self.P[u])\n",
        "        self.Q[i] = self.Q[i] + self.alpha * (error * self.P[u] - self.lamb * self.Q[i])\n",
        "        \n",
        "    def mae(self,  x_train, y_train):\n",
        "        \"\"\"\n",
        "        returns the Mean Absolute Error\n",
        "        \"\"\"\n",
        "        # number of training exemples\n",
        "        M = x_train.shape[0]\n",
        "        error = 0\n",
        "        for pair, r in zip(x_train, y_train):\n",
        "            u, i = pair\n",
        "            error += abs(r - np.dot(self.P[u], self.Q[i]))\n",
        "        return error/M\n",
        "    \n",
        "    def print_training_progress(self, epoch, epochs, error, val_error, steps=5):\n",
        "        if epoch == 1 or epoch % steps == 0 :\n",
        "                print(\"epoch {}/{} - loss : {} - val_loss : {}\".format(epoch, epochs, round(error,3), round(val_error,3)))\n",
        "                \n",
        "    def learning_rate_schedule(self, epoch, target_epochs = 20):\n",
        "        if (epoch >= target_epochs) and (epoch % target_epochs == 0):\n",
        "                factor = epoch // target_epochs\n",
        "                self.alpha = self.alpha * (1 / (factor * 20))\n",
        "                print(\"\\nLearning Rate : {}\\n\".format(self.alpha))\n",
        "    \n",
        "    def fit(self, x_train, y_train, validation_data, epochs=1000):\n",
        "        \"\"\"\n",
        "        Train latent factors P and Q according to the training set\n",
        "        \n",
        "        :param\n",
        "            - x_train : training pairs (u,i) for which rating r_ui is known\n",
        "            - y_train : set of ratings r_ui for all training pairs (u,i)\n",
        "            - validation_data : tuple (x_test, y_test)\n",
        "            - epochs : number of time to loop over the entire training set. \n",
        "            1000 epochs by default\n",
        "            \n",
        "        Note that u and i are encoded values of userid and itemid\n",
        "        \"\"\"\n",
        "        self.print_training_parameters()\n",
        "        \n",
        "        # validation data\n",
        "        x_test, y_test = validation_data\n",
        "        \n",
        "        # loop over the number of epochs\n",
        "        for epoch in range(1, epochs+1):\n",
        "            \n",
        "            # for each pair (u,i) and the corresponding rating r\n",
        "            for pair, r in zip(x_train, y_train):\n",
        "                \n",
        "                # get encoded values of userid and itemid from pair\n",
        "                u,i = pair\n",
        "                \n",
        "                # compute the predicted rating r_hat\n",
        "                r_hat = np.dot(self.P[u], self.Q[i])\n",
        "                \n",
        "                # compute the prediction error\n",
        "                e = abs(r - r_hat)\n",
        "                \n",
        "                # update rules\n",
        "                self.update_rule(u, i, e)\n",
        "                \n",
        "            # training and validation error  after this epochs\n",
        "            error = self.mae(x_train, y_train)\n",
        "            val_error = self.mae(x_test, y_test)\n",
        "            \n",
        "            # update history\n",
        "            self.history['epochs'].append(epoch)\n",
        "            self.history['loss'].append(error)\n",
        "            self.history['val_loss'].append(val_error)\n",
        "            \n",
        "            # update history\n",
        "            self.update_history(epoch, error, val_error)\n",
        "            \n",
        "            # print training progress after each steps epochs\n",
        "            self.print_training_progress(epoch, epochs, error, val_error, steps=1)\n",
        "              \n",
        "            # leaning rate scheduler : redure the learning rate as we go deeper in the number of epochs\n",
        "            # self.learning_rate_schedule(epoch)\n",
        "        \n",
        "        return self.history\n",
        "    \n",
        "    def update_history(self, epoch, error, val_error):\n",
        "        self.history['epochs'].append(epoch)\n",
        "        self.history['loss'].append(error)\n",
        "        self.history['val_loss'].append(val_error)\n",
        "        self.history['lr'].append(self.alpha)\n",
        "    \n",
        "    def evaluate(self, x_test, y_test):\n",
        "        \"\"\"\n",
        "        compute the global error on the test set        \n",
        "        :param x_test : test pairs (u,i) for which rating r_ui is known\n",
        "        :param y_test : set of ratings r_ui for all test pairs (u,i)\n",
        "        \"\"\"\n",
        "        error = self.mae(x_test, y_test)\n",
        "        print(f\"validation error : {round(error,3)}\")\n",
        "        \n",
        "        return error\n",
        "      \n",
        "    def predict(self, userid, itemid):\n",
        "        \"\"\"\n",
        "        Make rating prediction for a user on an item\n",
        "        :param userid\n",
        "        :param itemid\n",
        "        :return r : predicted rating\n",
        "        \"\"\"\n",
        "        # encode user and item ids to be able to access their latent factors in\n",
        "        # matrices P and Q\n",
        "        u = uencoder.transform([userid])[0]\n",
        "        i = iencoder.transform([itemid])[0]\n",
        "\n",
        "        # rating prediction using encoded ids. Dot product between P_u and Q_i\n",
        "        r = np.dot(self.P[u], self.Q[i])\n",
        "        return r\n",
        "\n",
        "    def recommend(self, userid, N=30):\n",
        "        \"\"\"\n",
        "        make to N recommendations for a given user\n",
        "\n",
        "        :return(top_items,preds) : top N items with the highest predictions \n",
        "        with their corresponding predictions\n",
        "        \"\"\"\n",
        "        # encode the userid\n",
        "        u = uencoder.transform([userid])[0]\n",
        "\n",
        "        # predictions for users userid on all product\n",
        "        predictions = np.dot(self.P[u], self.Q.T)\n",
        "\n",
        "        # get the indices of the top N predictions\n",
        "        top_idx = np.flip(np.argsort(predictions))[:N]\n",
        "\n",
        "        # decode indices to get their corresponding itemids\n",
        "        top_items = iencoder.inverse_transform(top_idx)\n",
        "\n",
        "        # take corresponding predictions for top N indices\n",
        "        preds = predictions[top_idx]\n",
        "\n",
        "        return top_items, preds     "
      ],
      "metadata": {
        "id": "7o_Xi4aDknaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10"
      ],
      "metadata": {
        "id": "ovb4RkGmkuMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MovieLens 100k\n",
        "\n",
        "Evaluasi rating mentah"
      ],
      "metadata": {
        "id": "_4edFQF3kw0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the ml100k dataset\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "m = ratings.userid.nunique()   # total number of users\n",
        "n = ratings.itemid.nunique()   # total number of items\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnonWIsFk0nt",
        "outputId": "4d585ea8-135e-443d-cfbf-10c995375c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download data 100.2%\n",
            "Successfully downloaded ml-100k.zip 4924029 bytes.\n",
            "Unzipping the ml-100k.zip zip file ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "MF = MatrixFactorization(m, n, k=10, alpha=0.01, lamb=1.5)\n",
        "\n",
        "# fit the model on the training set\n",
        "history = MF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtughig2k33A",
        "outputId": "2ac6aa82-1056-4d75-8b6d-64e785316980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Matrix Factorization Model ...\n",
            "k=10 \t alpha=0.01 \t lambda=1.5\n",
            "epoch 1/10 - loss : 2.734 - val_loss : 2.779\n",
            "epoch 2/10 - loss : 1.764 - val_loss : 1.794\n",
            "epoch 3/10 - loss : 1.592 - val_loss : 1.614\n",
            "epoch 4/10 - loss : 1.538 - val_loss : 1.556\n",
            "epoch 5/10 - loss : 1.515 - val_loss : 1.531\n",
            "epoch 6/10 - loss : 1.503 - val_loss : 1.517\n",
            "epoch 7/10 - loss : 1.496 - val_loss : 1.509\n",
            "epoch 8/10 - loss : 1.491 - val_loss : 1.504\n",
            "epoch 9/10 - loss : 1.488 - val_loss : 1.5\n",
            "epoch 10/10 - loss : 1.486 - val_loss : 1.497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MF.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxU6sJWrk6sQ",
        "outputId": "153811a7-d3f8-4490-b102-d07158b5326c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation error : 1.497\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4973507972141993"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluasi pada Rating yang dinormalisasi"
      ],
      "metadata": {
        "id": "Zs_izlayk9Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "m = ratings['userid'].nunique()   # total number of users\n",
        "n = ratings['itemid'].nunique()   # total number of items\n",
        "\n",
        "# normalize ratings by substracting means\n",
        "normalized_column_name = \"norm_rating\"\n",
        "ratings = normalized_ratings(ratings, norm_column=normalized_column_name)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column=normalized_column_name)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "id": "ZkDtf7x-k-uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "MF = MatrixFactorization(m, n, k=10, alpha=0.01, lamb=1.5)\n",
        "\n",
        "# fit the model on the training set\n",
        "history = MF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCfwwskclJmz",
        "outputId": "678afa8c-3755-4da2-86b0-8d98ad1f8637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Matrix Factorization Model ...\n",
            "k=10 \t alpha=0.01 \t lambda=1.5\n",
            "epoch 1/10 - loss : 0.851 - val_loss : 0.847\n",
            "epoch 2/10 - loss : 0.831 - val_loss : 0.831\n",
            "epoch 3/10 - loss : 0.828 - val_loss : 0.829\n",
            "epoch 4/10 - loss : 0.827 - val_loss : 0.828\n",
            "epoch 5/10 - loss : 0.827 - val_loss : 0.828\n",
            "epoch 6/10 - loss : 0.826 - val_loss : 0.828\n",
            "epoch 7/10 - loss : 0.826 - val_loss : 0.828\n",
            "epoch 8/10 - loss : 0.826 - val_loss : 0.828\n",
            "epoch 9/10 - loss : 0.826 - val_loss : 0.828\n",
            "epoch 10/10 - loss : 0.826 - val_loss : 0.828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MF.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1Wt4DBNlL9w",
        "outputId": "ca8a5c56-b443-4991-e9a1-8e2a329906ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation error : 0.828\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8276982643684648"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MovieLens 1M\n",
        "\n",
        "Evaluasi pada baris data"
      ],
      "metadata": {
        "id": "M_G4oApElQAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the ml1m dataset\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "m = ratings.userid.nunique()   # total number of users\n",
        "n = ratings.itemid.nunique()   # total number of items\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJQTAqwclSXI",
        "outputId": "fe4ecbd7-8f68-4cf8-eb66-1217ba036b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download data 100.1%\n",
            "Successfully downloaded ml-1m.zip 5917549 bytes.\n",
            "Unzipping the ml-1m.zip zip file ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "MF = MatrixFactorization(m, n, k=10, alpha=0.01, lamb=1.5)\n",
        "\n",
        "# fit the model on the training set\n",
        "history = MF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_tKdpMblX5j",
        "outputId": "78808f78-e454-4be3-f122-752354ea0136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Matrix Factorization Model ...\n",
            "k=10 \t alpha=0.01 \t lambda=1.5\n",
            "epoch 1/10 - loss : 0.851 - val_loss : 0.847\n",
            "epoch 2/10 - loss : 0.831 - val_loss : 0.831\n",
            "epoch 3/10 - loss : 0.828 - val_loss : 0.829\n",
            "epoch 4/10 - loss : 0.827 - val_loss : 0.828\n",
            "epoch 5/10 - loss : 0.827 - val_loss : 0.828\n",
            "epoch 6/10 - loss : 0.826 - val_loss : 0.828\n",
            "epoch 7/10 - loss : 0.826 - val_loss : 0.828\n",
            "epoch 8/10 - loss : 0.826 - val_loss : 0.828\n",
            "epoch 9/10 - loss : 0.826 - val_loss : 0.828\n",
            "epoch 10/10 - loss : 0.826 - val_loss : 0.828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluasi data pada Rating yang dinornalisasi"
      ],
      "metadata": {
        "id": "-sopa5X-lbKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "m = ratings['userid'].nunique()   # total number of users\n",
        "n = ratings['itemid'].nunique()   # total number of items\n",
        "\n",
        "# normalize ratings by substracting means\n",
        "normalized_column_name = \"norm_rating\"\n",
        "ratings = normalized_ratings(ratings, norm_column=normalized_column_name)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column=normalized_column_name)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "id": "d-cCAKqmleQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a51e441-a3c8-4d81-b35a-d13e0b0ad0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download data 100.1%\n",
            "Successfully downloaded ml-1m.zip 5917549 bytes.\n",
            "Unzipping the ml-1m.zip zip file ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "MF = MatrixFactorization(m, n, k=10, alpha=0.01, lamb=1.5)\n",
        "\n",
        "# fit the model on the training set\n",
        "history = MF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "J2jpH4L8lh4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a5e993-d376-4929-d3b9-9b84d1fb8bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Matrix Factorization Model ...\n",
            "k=10 \t alpha=0.01 \t lambda=1.5\n",
            "epoch 1/10 - loss : 0.826 - val_loss : 0.827\n",
            "epoch 2/10 - loss : 0.824 - val_loss : 0.825\n",
            "epoch 3/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 4/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 5/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 6/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 7/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 8/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 9/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 10/10 - loss : 0.823 - val_loss : 0.825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediksi"
      ],
      "metadata": {
        "id": "3zRXKPBllpDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.userid = uencoder.inverse_transform(ratings.userid.to_list())\n",
        "ratings.itemid = uencoder.inverse_transform(ratings.itemid.to_list())\n",
        "ratings.head(5)"
      ],
      "metadata": {
        "id": "4hW2RkOrlqFh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ad663595-278f-4d71-ce35-aad06195f8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userid  itemid  rating  rating_mean  norm_rating\n",
              "0       1       1       5     4.188679     0.811321\n",
              "1       1      48       5     4.188679     0.811321\n",
              "2       1     145       5     4.188679     0.811321\n",
              "3       1     254       4     4.188679    -0.188679\n",
              "4       1     514       5     4.188679     0.811321"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0769707-9ef5-4561-b2eb-4e1be49634c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userid</th>\n",
              "      <th>itemid</th>\n",
              "      <th>rating</th>\n",
              "      <th>rating_mean</th>\n",
              "      <th>norm_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4.188679</td>\n",
              "      <td>0.811321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>5</td>\n",
              "      <td>4.188679</td>\n",
              "      <td>0.811321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>5</td>\n",
              "      <td>4.188679</td>\n",
              "      <td>0.811321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>254</td>\n",
              "      <td>4</td>\n",
              "      <td>4.188679</td>\n",
              "      <td>-0.188679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>514</td>\n",
              "      <td>5</td>\n",
              "      <td>4.188679</td>\n",
              "      <td>0.811321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0769707-9ef5-4561-b2eb-4e1be49634c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b0769707-9ef5-4561-b2eb-4e1be49634c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b0769707-9ef5-4561-b2eb-4e1be49634c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "4.188679 + MF.predict(userid=1, itemid=1) # add the mean because we have used the normalised rating"
      ],
      "metadata": {
        "id": "GwZLgjshlwJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f1fd6b-c46f-4845-e225-a9242b0384cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.188679163563357"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kesimpulan:\n",
        "1.\tDengan model Faktorisasi Matriks, P dan Q faktor laten tidak dapat ditafsirkan karena mengandung nilai negatif atau positif yang berubah-ubah. Ini membuat model Faktorisasi Matriks menjadi tidak dapat dijelaskan.\n",
        "2.\tAlgoritma Faktorisasi Matriks Non-negatif (NMF) adalah varian dari Faktorisasi Matriks yang menghasilkan faktor laten yang dapat dijelaskan untuk dan dengan membatasi nilainya dalam kisaran [0,1]. Ini memungkinkan interpretasi probabilitas dari faktor-faktor laten ini, sehingga dapat dijelaskan.\n"
      ],
      "metadata": {
        "id": "hXv2h-yzGuYq"
      }
    }
  ]
}