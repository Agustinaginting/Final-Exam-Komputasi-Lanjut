{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Agustinaginting/Final-Exam-Komputasi-Lanjut/blob/main/Performances_Measure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Tools"
      ],
      "metadata": {
        "id": "7M1kv1QGfA5d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P36ibNYP8nEA"
      },
      "outputs": [],
      "source": [
        "#Download Tools\n",
        "import os\n",
        "\n",
        "if not (os.path.exists(\"recsys.zip\") or os.path.exists(\"recsys\")):\n",
        "    !wget https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip    \n",
        "    !unzip recsys.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m3i6RKR8nEB"
      },
      "source": [
        "### Persyaratan \n",
        "\n",
        "```\n",
        "matplotlib==3.2.2\n",
        "numpy==1.19.2\n",
        "pandas==1.0.5\n",
        "python==3.7\n",
        "scikit-learn==0.24.1\n",
        "scikit-surprise==1.1.1\n",
        "scipy==1.6.2\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmA_FpRo8nEB"
      },
      "outputs": [],
      "source": [
        "#Import Packages\n",
        "from recsys.memories.UserToUser import UserToUser\n",
        "from recsys.memories.ItemToItem import ItemToItem\n",
        "\n",
        "from recsys.models.MatrixFactorization import MF\n",
        "from recsys.models.ExplainableMF import EMF, explainable_score\n",
        "\n",
        "from recsys.preprocessing import normalized_ratings\n",
        "from recsys.preprocessing import train_test_split\n",
        "from recsys.preprocessing import rating_matrix\n",
        "from recsys.preprocessing import scale_ratings\n",
        "from recsys.preprocessing import mean_ratings\n",
        "from recsys.preprocessing import get_examples\n",
        "from recsys.preprocessing import ids_encoder\n",
        "\n",
        "from recsys.datasets import ml100k\n",
        "from recsys.datasets import ml1m\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dsi66zJ8nEB"
      },
      "source": [
        "# 1. Results on MovieLens 100k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXZvUIXW8nEB"
      },
      "source": [
        "## 1.1. User-based CF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "043osvxn8nEC",
        "outputId": "97e40696-7a96-48a9-ec2b-5e3934702983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "==========================\n",
            "Evaluate the model on 10000 test data ...\n",
            "\n",
            "MAE : 0.8125945111976461\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8125945111976461"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# prepare data\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column='rating')\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
        "\n",
        "# evaluate with Euclidean distance\n",
        "usertouser = UserToUser(ratings, movies, metric='euclidean')\n",
        "print(\"==========================\")\n",
        "usertouser.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation with cosine similarity"
      ],
      "metadata": {
        "id": "_mibeZAMgiBX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kaxJbqb8nEC",
        "outputId": "5129fa3f-59a8-46e0-a7b6-461a543a84f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "=========================\n",
            "Evaluate the model on 10000 test data ...\n",
            "\n",
            "MAE : 0.7505910931068639\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7505910931068639"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate with cosine similarity\n",
        "usertouser = UserToUser(ratings, movies, metric='cosine')\n",
        "print(\"=========================\")\n",
        "usertouser.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkgjp2Ef8nED"
      },
      "source": [
        "## 1.2. Item-based CF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmEM0JoN8nED",
        "outputId": "00e12759-09d4-4fd8-c87d-e5a19d39bca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalize ratings ...\n",
            "Create the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "Item to item recommendation model created with success ...\n",
            "==================\n",
            "Evaluate the model on 10000 test data ...\n",
            "\n",
            "MAE : 0.507794195659005\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.507794195659005"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# prepare data\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column='rating')\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
        "\n",
        "# evaluation with cosine similarity\n",
        "itemtoitem = ItemToItem(ratings, movies, metric='cosine')\n",
        "print(\"==================\")\n",
        "itemtoitem.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7M33bGT8nED"
      },
      "source": [
        "### Evaluation with Euclidean distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koScf1VK8nED",
        "outputId": "75dba92c-0fea-4b15-a04f-75929606bda2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalize ratings ...\n",
            "Create the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "Item to item recommendation model created with success ...\n",
            "==================\n",
            "Evaluate the model on 10000 test data ...\n",
            "\n",
            "MAE : 0.8277111416143341\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8277111416143341"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluation with Euclidean distance\n",
        "itemtoitem = ItemToItem(ratings, movies, metric='euclidean')\n",
        "print(\"==================\")\n",
        "itemtoitem.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQdJ1bVR8nED"
      },
      "source": [
        "## 1.3. Matrix Factorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UI3rAztW8nEE"
      },
      "outputs": [],
      "source": [
        "#Banyak iterasi\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuSAbvt58nEE",
        "outputId": "cf4c1fa6-9a11-4e6c-a34b-cae78b29b43d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Matrix Factorization Model ...\n",
            "k=10 \t alpha=0.01 \t lambda=1.5\n",
            "epoch 1/10 - loss : 2.734 - val_loss : 2.779\n",
            "epoch 2/10 - loss : 1.764 - val_loss : 1.794\n",
            "epoch 3/10 - loss : 1.592 - val_loss : 1.614\n",
            "epoch 4/10 - loss : 1.538 - val_loss : 1.556\n",
            "epoch 5/10 - loss : 1.515 - val_loss : 1.531\n",
            "epoch 6/10 - loss : 1.503 - val_loss : 1.517\n",
            "epoch 7/10 - loss : 1.496 - val_loss : 1.509\n",
            "epoch 8/10 - loss : 1.491 - val_loss : 1.504\n",
            "epoch 9/10 - loss : 1.488 - val_loss : 1.5\n",
            "epoch 10/10 - loss : 1.486 - val_loss : 1.497\n"
          ]
        }
      ],
      "source": [
        "# load the ml100k dataset\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "m = ratings.userid.nunique()   # total number of users\n",
        "n = ratings.itemid.nunique()   # total number of items\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
        "\n",
        "# create and train the model\n",
        "mf = MF(m, n, k=10, alpha=0.01, lamb=1.5)\n",
        "\n",
        "# fit the model on the training set\n",
        "history = mf.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnpmrF5n8nEE"
      },
      "source": [
        "## 1.4. Non-negative Matrix Factorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwmUHnCV8nEE",
        "outputId": "92103572-5968-4236-fbc1-10a56356fe05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating MAE of algorithm NMF on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.9615  0.9501  0.9548  0.9582  0.9675  0.9584  0.0059  \n",
            "Fit time          0.67    0.72    0.79    0.72    0.72    0.72    0.04    \n",
            "Test time         0.15    0.09    0.16    0.10    0.14    0.13    0.03    \n"
          ]
        }
      ],
      "source": [
        "from surprise import NMF\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# Load the movielens-100k dataset (download it if needed).\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# Use the NMF algorithm.\n",
        "nmf = NMF(n_factors=10, n_epochs=10)\n",
        "\n",
        "# Run 5-fold cross-validation and print results.\n",
        "history = cross_validate(nmf, data, measures=['MAE'], cv=5, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3cacpSR8nEE"
      },
      "source": [
        "## 1.5. Explainable Matrix Factorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FL9PZGM8nEE",
        "outputId": "3c67be2a-6b6e-45b8-982e-6da5843b5e22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "Compute explainable scores ...\n",
            "===================\n",
            "Training EMF\n",
            "k=10 \t alpha=0.01 \t beta=0.4 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.922 - val_loss : 1.036\n",
            "epoch 2/10 - loss : 0.79 - val_loss : 0.873\n",
            "epoch 3/10 - loss : 0.766 - val_loss : 0.837\n",
            "epoch 4/10 - loss : 0.757 - val_loss : 0.822\n",
            "epoch 5/10 - loss : 0.753 - val_loss : 0.814\n",
            "epoch 6/10 - loss : 0.751 - val_loss : 0.808\n",
            "epoch 7/10 - loss : 0.749 - val_loss : 0.805\n",
            "epoch 8/10 - loss : 0.748 - val_loss : 0.802\n",
            "epoch 9/10 - loss : 0.746 - val_loss : 0.799\n",
            "epoch 10/10 - loss : 0.745 - val_loss : 0.797\n",
            "===================\n",
            "MAE : 0.797\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7973478247232839"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "users = sorted(ratings.userid.unique())\n",
        "items = sorted(ratings.itemid.unique())\n",
        "\n",
        "m = len(users)\n",
        "n = len(items)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
        "\n",
        "# create the user to user model for similarity measure\n",
        "usertouser = UserToUser(ratings, movies)\n",
        "\n",
        "# compute explainable score\n",
        "W = explainable_score(usertouser, users, items)\n",
        "\n",
        "print(\"===================\")\n",
        "# initialize the model\n",
        "emf = EMF(m, n, W, alpha=0.01, beta=0.4, lamb=0.01, k=10)\n",
        "\n",
        "history = emf.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))\n",
        "\n",
        "print(\"===================\")\n",
        "emf.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azAfE1mX8nEE"
      },
      "source": [
        "# 3. Results on MovieLens 1M (ML-1M)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTzK9z-H8nEE"
      },
      "source": [
        "## 3.1. User-based CF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kw88_Uz8nEF",
        "outputId": "51848d4f-4906-4600-9cd6-2b91b15483d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "==========================\n",
            "Evaluate the model on 100021 test data ...\n",
            "\n",
            "MAE : 0.732267005840993\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.732267005840993"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load ml100k ratings\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "# prepare data\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column='rating')\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
        "\n",
        "# metric : cosine\n",
        "\n",
        "# create the user-based CF\n",
        "usertouser = UserToUser(ratings, movies, k=20, metric='cosine')\n",
        "\n",
        "# evaluate the user-based CF on the ml1m test data\n",
        "print(\"==========================\")\n",
        "usertouser.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-27zeUU8nEF",
        "outputId": "cdef05fb-4443-4a3f-f1be-891473e88609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "==========================\n",
            "Evaluate the model on 100021 test data ...\n",
            "\n",
            "MAE : 0.8069332535426615\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8069332535426615"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# metric : euclidean\n",
        "\n",
        "# create the user-based CF\n",
        "usertouser = UserToUser(ratings, movies, k=20, metric='euclidean')\n",
        "\n",
        "# evaluate the user-based CF on the ml1m test data\n",
        "print(\"==========================\")\n",
        "usertouser.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXgDuGf88nEF"
      },
      "source": [
        "## 3.2. Item-based CF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgZ9jm9d8nEF"
      },
      "source": [
        "### Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJIAagig8nEF",
        "outputId": "685bed7e-d50e-4118-aa68-38aba9134b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalize ratings ...\n",
            "Create the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "Item to item recommendation model created with success ...\n",
            "==========================\n",
            "Evaluate the model on 100021 test data ...\n",
            "\n",
            "MAE : 0.42514728655396045\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.42514728655396045"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#cosine Similarity\n",
        "itemtoitem = ItemToItem(ratings, movies, metric='cosine')\n",
        "print(\"==========================\")\n",
        "itemtoitem.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSDNXcsA8nEF"
      },
      "source": [
        "### Euclidean distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XR_CebQ-8nEF",
        "outputId": "3b15cc54-beb6-478e-e594-1e8edac0e7a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalize ratings ...\n",
            "Create the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "Item to item recommendation model created with success ...\n",
            "==========================\n",
            "Evaluate the model on 100021 test data ...\n",
            "\n",
            "MAE : 0.82502173206615\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.82502173206615"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Euclidean Distance\n",
        "itemtoitem = ItemToItem(ratings, movies, metric='euclidean')\n",
        "print(\"==========================\")\n",
        "itemtoitem.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phq5higT8nEG"
      },
      "source": [
        "## 3.3. Matrix Factorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKP-vRjX8nEG",
        "outputId": "122a8c25-27cc-4652-e955-fc9a01855fe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Matrix Factorization Model ...\n",
            "k=10 \t alpha=0.01 \t lambda=1.5\n",
            "epoch 1/10 - loss : 1.713 - val_loss : 1.718\n",
            "epoch 2/10 - loss : 1.523 - val_loss : 1.526\n",
            "epoch 3/10 - loss : 1.496 - val_loss : 1.498\n",
            "epoch 4/10 - loss : 1.489 - val_loss : 1.489\n",
            "epoch 5/10 - loss : 1.485 - val_loss : 1.486\n",
            "epoch 6/10 - loss : 1.484 - val_loss : 1.484\n",
            "epoch 7/10 - loss : 1.483 - val_loss : 1.483\n",
            "epoch 8/10 - loss : 1.483 - val_loss : 1.483\n",
            "epoch 9/10 - loss : 1.482 - val_loss : 1.482\n",
            "epoch 10/10 - loss : 1.482 - val_loss : 1.482\n",
            "===================\n",
            "validation error : 1.482\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.4820034560467208"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the ml1m dataset\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "m = ratings.userid.nunique()   # total number of users\n",
        "n = ratings.itemid.nunique()   # total number of items\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
        "\n",
        "# create the model\n",
        "model = MF(m, n, k=10, alpha=0.01, lamb=1.5)\n",
        "\n",
        "# fit the model on the training set\n",
        "history = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))\n",
        "\n",
        "print(\"===================\")\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tdwZWF98nEG"
      },
      "source": [
        "## 3.4. Non-negative Matrix Factorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB3ZYxHU8nEG",
        "outputId": "783b8e65-9364-4520-d926-651445deb915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating MAE of algorithm NMF on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.9435  0.9456  0.9527  0.9546  0.9524  0.9498  0.0044  \n",
            "Fit time          6.35    6.51    6.52    6.52    6.55    6.49    0.07    \n",
            "Test time         1.20    1.47    1.46    1.47    1.47    1.42    0.11    \n"
          ]
        }
      ],
      "source": [
        "from surprise import NMF\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# Load the movielens-100k dataset (download it if needed).\n",
        "data = Dataset.load_builtin('ml-1m')\n",
        "\n",
        "# Use the NMF algorithm.\n",
        "nmf = NMF(n_factors=10, n_epochs=10)\n",
        "\n",
        "# Run 5-fold cross-validation and print results.\n",
        "history = cross_validate(nmf, data, measures=['MAE'], cv=5, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCs6LZPy8nEG"
      },
      "source": [
        "## 3.5. Explainable Matrix Factorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpnKm3A78nEG",
        "outputId": "daa14cca-ed5e-4e61-e735-721b316963fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "Compute explainable scores ...\n",
            "Training EMF\n",
            "k=10 \t alpha=0.01 \t beta=0.4 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.782 - val_loss : 0.807\n",
            "epoch 2/10 - loss : 0.762 - val_loss : 0.781\n",
            "epoch 3/10 - loss : 0.76 - val_loss : 0.775\n",
            "epoch 4/10 - loss : 0.758 - val_loss : 0.771\n",
            "epoch 5/10 - loss : 0.757 - val_loss : 0.769\n",
            "epoch 6/10 - loss : 0.756 - val_loss : 0.767\n",
            "epoch 7/10 - loss : 0.754 - val_loss : 0.764\n",
            "epoch 8/10 - loss : 0.752 - val_loss : 0.762\n",
            "epoch 9/10 - loss : 0.751 - val_loss : 0.761\n",
            "epoch 10/10 - loss : 0.75 - val_loss : 0.76\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "users = sorted(ratings.userid.unique())\n",
        "items = sorted(ratings.itemid.unique())\n",
        "\n",
        "m = len(users)\n",
        "n = len(items)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)\n",
        "\n",
        "# create the user to user model for similarity measure\n",
        "usertouser = UserToUser(ratings, movies)\n",
        "\n",
        "# compute explainable score\n",
        "W = explainable_score(usertouser, users, items)\n",
        "\n",
        "# initialize the model\n",
        "emf = EMF(m, n, W, alpha=0.01, beta=0.4, lamb=0.01, k=10)\n",
        "\n",
        "history = emf.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBDG_9-p8nEG"
      },
      "source": [
        "## Summary\n",
        "\n",
        "<center> <b> MAE comparison between User-based and Item-based CF </b> </center>\n",
        "\n",
        "|   Metric  | Dataset | User-based | Item-based |\n",
        "|:---------:|:-------:|:----------:|:----------:|\n",
        "| Euclidean | ML-100k |    0.81    |    0.83    |\n",
        "| Euclidean |  ML-1M  |    0.81    |    0.82    |\n",
        "|   Cosine  | ML-100k |    0.75    |    0.51    |\n",
        "|   Cosine  |  ML-1M  |    0.73    |    0.42    |\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<center> <b> MAE comparison between MF, NMF and EMF </b> </center>\n",
        "\n",
        "|  Preprocessing  | Dataset |   MF  |   NMF  | EMF   |\n",
        "|:---------------:|:-------:|:-----:|:------:|-------|\n",
        "|     Raw data    | ML-100k | 1.497 |  0.951 | 0.797 |\n",
        "|     Raw data    |  ML-1M  | 1.482 | 0.9567 | 0.76  |\n",
        "| Normalized data | ML-100k | 0.828 |   ---  | 0.783 |\n",
        "| Normalized data |  ML-1M  | 0.825 |   ---  | 0.758 |\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}